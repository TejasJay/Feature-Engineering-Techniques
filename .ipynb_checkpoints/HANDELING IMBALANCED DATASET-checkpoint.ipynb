{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b81b7b1",
   "metadata": {},
   "source": [
    "# Handeling Imbalanced Data\n",
    "- Under Sampling\n",
    "- Over Sampling\n",
    "- SMOTETOmek\n",
    "- EasyEnsembleClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset from kaggle\n",
    "\n",
    "# https://www.kaggle.com/mlg-ulb/creditcardfraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd285d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.1-py3-none-any.whl (189 kB)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.24 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.24.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\tejas\\anaconda3\\lib\\site-packages (from scikit-learn>=0.24->imbalanced-learn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.8.1\n"
     ]
    }
   ],
   "source": [
    "# Installing imbalanced learn package\n",
    "\n",
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1fbf841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and reading the data\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(r'C:\\Users\\tejas\\Desktop\\ineuron\\feature engineering\\data\\creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20db29b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for missing values\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d0b1631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it can be seen that the data is heavily imbalanced because the number of fraudulent \n",
    "# transactions are very less when compared to the fraudlent classes\n",
    "\n",
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47caaf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Independent and Dependent Features\n",
    "\n",
    "X=df.drop(\"Class\",axis=1)\n",
    "y=df.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3685f7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c298f14b",
   "metadata": {},
   "source": [
    "### Let us test the dataset and metrics by Performing simple model training using Logistic Regression without any sampling techniques, using Cross Validation KFOLD and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fd68581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's test with Logistic Regression\n",
    "\n",
    "# importing the libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b25c7feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting values for hyper parameter C in this range\n",
    "\n",
    "10.0 **np.arange(-2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9656cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calling the logistic regression class\n",
    "log_class = LogisticRegression()\n",
    "\n",
    "# hyperparameter for grid search\n",
    "grid = {'C':10.0 **np.arange(-2,3),'penalty':['l1','l2']}\n",
    "\n",
    "# cross validation using kflod technique\n",
    "cv = KFold(n_splits=5,random_state=None,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8403cd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16ea3df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tejas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [       nan 0.8080668         nan 0.83033146        nan 0.82772467\n",
      "        nan 0.83158855        nan 0.82770613]\n",
      "  warnings.warn(\n",
      "C:\\Users\\tejas\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='f1_macro')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fitting the model with train test split\n",
    "\n",
    "clf = GridSearchCV(log_class,grid,cv=cv,n_jobs=-1,scoring='f1_macro')\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6004a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85268    32]\n",
      " [   45    98]]\n",
      "0.9990988144142879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85300\n",
      "           1       0.75      0.69      0.72       143\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.88      0.84      0.86     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting the result using the test data\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# outputing the prediction as a report\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e786b38",
   "metadata": {},
   "source": [
    "#### It can be evidently seen that there are many False positives and False Negetavies and the F1 score isn't that great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23404a6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "520df774",
   "metadata": {},
   "source": [
    "### It has been told that imbalanced dataset does not effect algorithms like decision trees or ensemble techniques algorithms, so let's test to check if that is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac5d39de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight={0: 1, 1: 100})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing and \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# we give class weight to tell that class 0 has weight ratio equal to 1, \n",
    "#where as class 1 has its weight equal to 100 because there are very less values in class 1\n",
    "class_weight = dict({0:1, 1:100})\n",
    "\n",
    "\n",
    "classifier=RandomForestClassifier(class_weight= class_weight)\n",
    "\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0aa4274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85296     4]\n",
      " [   26   117]]\n",
      "0.9996488887328394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85300\n",
      "           1       0.97      0.82      0.89       143\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.91      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting the result with the test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# printing the result of the metrics\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b91545",
   "metadata": {},
   "source": [
    "#### It can be seen that the number of False positives and False Negetavies have reduced after using RandomForestClassifier. But still we need to get down the FP and FN rate and increase the precision, Recall and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46004326",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06e64c63",
   "metadata": {},
   "source": [
    "## Under Sampling\n",
    "- Random undersampling involves randomly deleting events from the majority class. Instead of getting rid of events at random, we can use some type of reasoning for keeping versus getting rid of some data.\n",
    "- Near Miss refers to a collection of undersampling methods that select examples based on the distance of majority class examples to minority class examples. NearMiss-1 selects examples from the majority class that have the smallest average distance to the three closest examples from the minority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95e80aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 199015, 1: 349})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for original class labels and its values\n",
    "# used to display the classes\n",
    "\n",
    "from collections import Counter \n",
    "\n",
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3cec0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 199015, 1: 349})\n",
      "The number of classes after fit Counter({0: 436, 1: 349})\n"
     ]
    }
   ],
   "source": [
    "# using under_sampling NearMiss technique to down sample the dataset\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# 0.8 refers to, downsampling class 0 such that, 80% of value counts of class 0 should be the value counts of 1\n",
    "ns=NearMiss(0.8)\n",
    "\n",
    "# fitting the train and test with the new sample data\n",
    "X_train_ns,y_train_ns=ns.fit_resample(X_train,y_train)\n",
    "\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d59c28dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with Random Forest after the undersampling technique\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_ns,y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf1cbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71863 13437]\n",
      " [    8   135]]\n",
      "accuracy:  0.8426436337675409\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91     85300\n",
      "           1       0.01      0.94      0.02       143\n",
      "\n",
      "    accuracy                           0.84     85443\n",
      "   macro avg       0.50      0.89      0.47     85443\n",
      "weighted avg       1.00      0.84      0.91     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting and outputting the metrics\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('accuracy: ',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76238ffe",
   "metadata": {},
   "source": [
    "#### It can be seen that the performance has decreased drastically when we look at precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33ecab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3d145a7",
   "metadata": {},
   "source": [
    "## Over Sampling\n",
    "- Oversampling uses imitation or synthetic techniques to increase the number of minority class samples to equal the number of majority class samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "968ea9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 199015, 1: 349})\n",
      "The number of classes after fit Counter({0: 199015, 1: 149261})\n"
     ]
    }
   ],
   "source": [
    "# importing random over sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# bringing up the values of class 1 to 75% of class 0\n",
    "os=RandomOverSampler(0.75)\n",
    "\n",
    "# fitting the train and test with the new sample data\n",
    "X_train_ns, y_train_ns = os.fit_resample(X_train,y_train)\n",
    "\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a54c4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with Random Forest after the oversampling technique\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train_ns, y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c91714a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85296     4]\n",
      " [   23   120]]\n",
      "accuracy:  0.9996839998595555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85300\n",
      "           1       0.97      0.84      0.90       143\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.98      0.92      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting and outputting the metrics\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('accuracy: ',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b36515",
   "metadata": {},
   "source": [
    "#### The performance increased drastically after oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0d7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "842a6d88",
   "metadata": {},
   "source": [
    "## SMOTETomek\n",
    "- SMOTE (synthetic minority oversampling technique) is one of the most commonly used oversampling methods to solve the imbalance problem. It aims to balance class distribution by randomly increasing minority class examples by replicating them. SMOTE synthesizes new minority instances between existing minority instances.\n",
    "- Calculate the distance between the random data and its k nearest neighbors. Multiply the difference with a random number between 0 and 1, then add the result to the minority class as a synthetic sample.\n",
    "- SMOTETOMEK is an interesting technique that combines both undersampling (using Tomek Links) and oversampling (using SMOTE), and this combination can bring you great results if used wisely. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87bfbc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of classes before fit Counter({0: 199015, 1: 349})\n",
      "The number of classes after fit Counter({0: 198189, 1: 148435})\n"
     ]
    }
   ],
   "source": [
    "# importing SMOTETomek library\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "# bringing up and down the values to 75%\n",
    "os = SMOTETomek(0.75)\n",
    "\n",
    "# fitting the train and test with the new sample data\n",
    "X_train_ns,y_train_ns = os.fit_resample(X_train,y_train)\n",
    "\n",
    "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
    "print(\"The number of classes after fit {}\".format(Counter(y_train_ns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c47ba791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing with Random Forest after the oversampling technique\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_train_ns, y_train_ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7b81770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85291     9]\n",
      " [   18   125]]\n",
      "accuracy:  0.9996839998595555\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85300\n",
      "           1       0.93      0.87      0.90       143\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.94      0.95     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting and outputting the metrics\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('accuracy: ',accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1d6383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6961f54a",
   "metadata": {},
   "source": [
    "## EasyEnsembleClassifier for imbalanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e38b434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EasyEnsembleClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "\n",
    "# calling the class\n",
    "easy = EasyEnsembleClassifier()\n",
    "\n",
    "# fitting the data\n",
    "easy.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e854e391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[82555  2745]\n",
      " [   10   133]]\n",
      "0.9677562819657549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     85300\n",
      "           1       0.05      0.93      0.09       143\n",
      "\n",
      "    accuracy                           0.97     85443\n",
      "   macro avg       0.52      0.95      0.54     85443\n",
      "weighted avg       1.00      0.97      0.98     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predicting the test\n",
    "y_pred=easy.predict(X_test)\n",
    "\n",
    "# printing the metrics\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044b21c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
